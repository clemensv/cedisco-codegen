{#- Kafka macros -#}

{%- macro KafkaHeaders() -%}
using Confluent.Kafka;
{%- endmacro -%}

{%- macro EmitArguments(props) -%}
{%- for propname, prop in props.items() %}
{%- if prop.type == "uritemplate" -%}
   {%- for placeholder in prop.value | regex_search('\\{([A-Za-z0-9_]+)\\}') -%}
   , string {{ placeholder }}
   {%- endfor -%}
{%- elif prop.value is not defined -%}
   , string {{ propname }}{%- if not prop.required %} = default {%- endif %}{% endif -%}
{%- endfor -%}
{%- endmacro -%}

{#- Generates a list of arguments for "send" methods that correspond to placeholders in uritemplates -#}
{%- macro DeclareUriTemplateArguments(message) -%}
{%- if message.protocoloptions["headers"] -%}{{ EmitArguments(message.protocoloptions["headers"]) }}{%- endif -%}
{%- if message.protocoloptions["key"] -%}{{ EmitArguments(message.protocoloptions["key"]) }}{%- endif -%}
{%- if message.protocoloptions["partition"] -%}{{ EmitArguments(message.protocoloptions["partition"]) }}{%- endif -%}
{%- if message.protocoloptions["topic"] -%}{{ EmitArguments(message.protocoloptions["topic"]) }}{%- endif -%}
{%- if message.protocoloptions["timestamp"] -%}{{ EmitArguments(message.protocoloptions["timestamp"]) }}{%- endif -%}
{%- endmacro %}

{#- Helper macro for assigning properties -#}
{%- macro AssignProps(target, props, as_dict = False) -%}
{%- for propname, prop in props.items() -%}
{%- if as_dict %}
["{{ propname }}"] = {% else %}
{{ target }}.{{ propname | pascal }} = {% endif -%}
{%- if prop.value -%}
   {%- if prop.type in ["integer", "number", "boolean"] -%}
      {{ prop.value }}
   {%- elif prop.type == "uri" or prop.type == "uritemplate" -%}
      new Uri($"{{ prop.value }}", UriKind.RelativeOrAbsolute),
   {%- else -%}
      $"{{ prop.value }}"
   {%- endif -%}
{%- else -%}
   {{ propname }}
{%- endif -%},
{%- endfor -%}
{%- endmacro -%}

{#- Generates Kafka message objects from kafkaDefinition as message -#}
{%- macro DeclareKafkaMessage(variable, message) -%}
{%- set headers = message.protocoloptions["headers"] %}
{%- set key = message.protocoloptions["key"] %}
{%- set partition = message.protocoloptions["partition"] %}
{%- set topic = message.protocoloptions["topic"] %}
{%- set timestamp = message.protocoloptions["timestamp"] %}
Message<byte[], byte[]> {{ variable }} = new Message<byte[], byte[]>();
{%- if headers %}
{{- AssignProps("{{ variable }}.Headers", headers, True) | indent(6) }}
{%- endif %}
{%- if key %}
{{- AssignProps("{{ variable }}.Key", key) | indent(6) }}
{%- endif %}
{%- if partition %}
{{- AssignProps("{{ variable }}.Partition", partition) | indent(6) }}
{%- endif %}
{%- if topic %}
{{- AssignProps("{{ variable }}.Topic", topic) | indent(6) }}
{%- endif %}
{%- if timestamp %}
{{- AssignProps("{{ variable }}.Timestamp", timestamp) | indent(6) }}
{%- endif %}
{%- endmacro -%}

{%- macro DeclareDispatchObjectsArgs(project_name, messagegroups, withType) -%}
{%- for messagegroupid, messagegroup in messagegroups.items() if (messagegroup | exists( "protocol", "kafka" )) -%}
{%- set messagegroupname = messagegroupid  | pascal %}
{%- if withType -%}global::{{ messagegroupname | namespace_dot(project_name) | pascal }}I{{ messagegroupname | strip_namespace }}Dispatcher {% endif %}{{ messagegroupid  | strip_namespace | camel }}KafkaDispatcher{%- if not loop.last %}, {%- endif -%}
{%- endfor %}
{%- endmacro-%}

{%- macro DeclareDispatchObjectField(project_name, messagegroup) %}
{%- set handlerName=(messagegroupid | strip_namespace | camel)+"KafkaDispatcher" -%}
{%- set handlerType=(messagegroupid  | namespace_dot(project_name) | pascal)+"I"+(messagegroupid | strip_namespace | pascal)+"KafkaDispatcher" %}
{{ handlerType }} {{ handlerName }};
{% endmacro -%}

{%- macro DeclareDispatchObjectsFields(project_name,messagegroups) %}
{%- for messagegroupid, messagegroup in messagegroups.items() if messagegroup | exists( "protocol", "kafka" ) %}
{{ DeclareDispatchObjectField( project_name, messagegroup ) }}
{%- endfor %}
{%- endmacro -%}


{%- macro DeclareDispatchObjectsConstructor(project_name, class_name, messagegroups, args, body) %}
{%- if messagegroups | exists( "protocol", "kafka" ) %}
public {{ class_name }}({{ args }}{%- if args %}, {%- endif -%}
    {%- for messagegroupid, messagegroup in messagegroups.items() if messagegroup | exists( "protocol", "kafka" ) -%}
    {%- set messagegroupname = messagegroupid  | pascal -%} 
    {%- set handlerName=(messagegroupid  | strip_namespace | camel)+"KafkaDispatcher" -%}
    {%- set handlerType=(messagegroupid  | namespace_dot(project_name) | pascal)+"I"+(messagegroupid  | strip_namespace | pascal)+"KafkaDispatcher" -%}
    {{ handlerType }} {{ handlerName }}
    {%- if not loop.last -%}, {%- endif -%}
    {%- endfor -%})
{
    {% for messagegroupid, messagegroup in messagegroups.items() if messagegroup | exists( "protocol", "kafka" ) -%}
    {%- set messagegroupname = messagegroupid  | pascal %}
    {%- set handlerName=(messagegroupid  | strip_namespace | camel)+"KafkaDispatcher" -%}
    {%- set handlerType=(messagegroupid  | namespace_dot(project_name) | pascal)+"I"+(messagegroupid  | strip_namespace | pascal)+"KafkaDispatcher" -%}
    this.{{ handlerName }} = {{ handlerName }};
    {%- endfor %}
    {{ body | indent(4) }}
}
{%- endif -%}
{%- endmacro -%}

{%- macro DispatchToDispatchObject(project_name, data_project_name, root, message, messagegroup, logger) -%}
var messageSubject = message.Headers.FirstOrDefault(h => h.Key == "subject")?.GetValueBytes() != null 
    ? Encoding.UTF8.GetString(message.Headers.FirstOrDefault(h => h.Key == "subject")?.GetValueBytes()) 
    : null;
switch (messageSubject)
{
   {%- set handlerName=(messagegroupid | strip_namespace | camel)+"KafkaDispatcher" -%}
   {% for messageid, message in messagegroup.messages.items() if (message | exists( "protocol", "kafka" )) -%}
   {% set messagename = messageid | pascal %}
   case "{{ messageid }}":
         if ( this.{{ handlerName }} != null )
         {
            await this.{{ handlerName }}.On{{ messagename | strip_namespace }}Async({{ message }},
               {%- if message.dataschemauri or message.dataschema -%}
            global::{{( message.dataschemauri if message.dataschemauri else message.dataschema) | schema_type( project_name, root, message.dataschemaformat)  | pascal }}.FromData({{ message }}.Value, {{ message }}.Headers.FirstOrDefault(h => h.Key == "content-type")?.GetValueBytes() != null ? Encoding.UTF8.GetString({{ message }}.Headers.FirstOrDefault(h => h.Key == "content-type")?.GetValueBytes()) : null)
            {%- else -%}
            {{ message }}.Data
            {%- endif %});
            break;
         }
         break;
   {% endfor %}
   default:
      {{ logger }}.LogError($"Unsupported message subject {messageSubject}");
      break;
}
{%- endmacro -%}

{%- macro DispatchToDispatchObjects(project_name, data_project_name, root, message, messagegroups, logger) -%}
{%- if messagegroups | exists( "protocol", "kafka" ) %}
var messageSubject = message.Headers.FirstOrDefault(h => h.Key == "subject")?.GetValueBytes() != null 
    ? Encoding.UTF8.GetString(message.Headers.FirstOrDefault(h => h.Key == "subject")?.GetValueBytes()) 
    : null;
switch (messageSubject)
{
   {% for messagegroupid, messagegroup in messagegroups.items() if (messagegroup | exists( "protocol", "kafka" )) -%}
   {%- set handlerName=(messagegroupid  | strip_namespace | camel)+"KafkaDispatcher" -%}
   {% for messageid, message in messagegroup.messages.items() if (message | exists( "protocol", "kafka" )) -%}
   {% set messagename = messageid | pascal %}
   case "{{ messageid }}":
         if ( this.{{ handlerName }} != null )
         {
            await this.{{ handlerName }}.On{{ messagename | strip_namespace }}Async({{ message }},
               {%- if message.dataschemauri or message.dataschema -%}
            global::{{( message.dataschemauri if message.dataschemauri else message.dataschema) | schema_type( data_project_name, root, message.dataschemaformat)  | pascal }}.FromData({{ message }}.Value, {{ message }}.Headers.FirstOrDefault(h => h.Key == "content-type")?.GetValueBytes() != null ? Encoding.UTF8.GetString({{ message }}.Headers.FirstOrDefault(h => h.Key == "content-type")?.GetValueBytes()) : null)
            {%- else -%}
            {{ message }}.Data
            {%- endif %});
            break;
         }
         break;
   {% endfor %}
   {% endfor %}
   default:
      {{ logger }}.LogError($"Unsupported message subject {messageSubject}");
      break;
}
{%- endif -%}
{%- endmacro -%}

{%- macro DeclareDispatchInterfaces(project_name, data_project_name, root) -%}
{%- set messagegroups = root.messagegroups -%}
{%- if messagegroups | exists( "protocol", "kafka" ) %}
{%- set function_name = project_name | pascal | strip_dots %}
using System.Threading.Tasks;
using Confluent.Kafka;
{%- for messagegroupid, messagegroup in messagegroups.items() if (messagegroup | exists( "protocol", "kafka" )) -%}
{%- set messagegroupname = messagegroupid  | pascal %}
namespace {{ messagegroupname | concat_namespace(project_name) | pascal }}
{
   public interface I{{ messagegroupname | strip_namespace }}KafkaDispatcher
   {
      {%- for messageid, message in messagegroup.messages.items() if (message | exists( "protocol", "kafka" )) -%}
      {%- set messagename = messageid | strip_namespace | pascal -%}
      {%- if message.dataschemauri or message.dataschema -%}
      {%- set dataType = 'global::' + (( message.dataschemauri if message.dataschemauri else message.dataschema) | schema_type( data_project_name, root, message.dataschemaformat)  | pascal) -%}
      {%- else -%}
      {%- set dataType = "object" -%}
      {%- endif %}
      {%- if message.description %}   
      /// <summary>
      /// {{ message.description }}
      /// </summary>
      {%- endif %}
      Task On{{ messagename | strip_namespace }}Async(Message<byte[], byte[]> message, {{ dataType }}? data);
      {%- endfor %}
   }
}
{%- endfor -%}
{%- endif -%}
{%- endmacro -%}

{%- macro CloudEventsUsings() -%}
using CloudNative.CloudEvents;
using CloudEvent = CloudNative.CloudEvents.CloudEvent;
using CloudNative.CloudEvents.Core;
using CloudNative.CloudEvents.SystemTextJson;
using CloudNative.CloudEvents.Protobuf;
using CloudNative.CloudEvents.Avro;
{%- endmacro -%}

{%- macro CloudEventsMethods() -%}
private static string[] ceAttribs = ["specversion", "dataschema", "time", "source", "subject", "type", "id"];
protected const string kafkaCloudEventPrefix = "ce_";
protected static readonly CloudEventFormatter jsonFormatter = new JsonEventFormatter();
protected static readonly CloudEventFormatter protoFormatter = new ProtobufEventFormatter();
protected static readonly CloudEventFormatter avroFormatter = new global::CloudNative.CloudEvents.Avro.AvroEventFormatter();

protected string? GetCloudEventAttribute(Message<byte[], byte[]> message, string key)
{
    _logger.LogInformation($"Getting CloudEvent attribute {key}");
    var header = message.Headers.FirstOrDefault(h => h.Key == kafkaCloudEventPrefix + key);
    return header?.GetValueBytes() != null ? Encoding.UTF8.GetString(header.GetValueBytes()) : null;
} 

protected bool IsCloudEvent(Message<byte[], byte[]> message)
{
    _logger.LogInformation("Checking if Message is a CloudEvent.");
    var contentTypeHeader = message.Headers.FirstOrDefault(h => h.Key == "content-type");
    var contentType = contentTypeHeader?.GetValueBytes() != null ? Encoding.UTF8.GetString(contentTypeHeader.GetValueBytes()) : null;
    return MimeUtilities.IsCloudEventsContentType(contentType) ||
           message.Headers.Any(h => h.Key == kafkaCloudEventPrefix + "specversion");
}


protected CloudEvent CloudEventFromMessage(Message<byte[], byte[]> message)
{
   try
   {
      _logger.LogInformation("Extracting CloudEvent from Message.");
      CloudEventFormatter? formatter = null;
      var contentTypeHeader = message.Headers.FirstOrDefault(h => h.Key == "content-type");
      var contentType = contentTypeHeader?.GetValueBytes() != null ? Encoding.UTF8.GetString(contentTypeHeader.GetValueBytes())?.Split(';')[0] : null;
      if (contentType != null && contentType.StartsWith("application/cloudevents"))
      {
         _logger.LogInformation($"Using structured mode for CloudEvent with content type {contentType}.");
         formatter = contentType.EndsWith("+proto") ? protoFormatter : contentType.EndsWith("+avro") ? avroFormatter : jsonFormatter;
         return formatter.DecodeStructuredModeMessage(new MemoryStream(message.Value), new System.Net.Mime.ContentType(contentType), null);
      }
      else
      {
         _logger.LogInformation("Using binary mode for CloudEvent.");
         var cloudEvent = new CloudEvent
         {
            Data = message.Value,
            DataContentType = contentType,
         };
         string? specVersion = GetCloudEventAttribute(message, "specversion");
         if (specVersion != "1.0") throw new Exception("Unsupported CloudEvent specversion: " + specVersion);
         string? dataSchema = GetCloudEventAttribute(message, "dataschema");         
         if (dataSchema != null) cloudEvent.DataSchema = new Uri(dataSchema, UriKind.RelativeOrAbsolute);
         string? time = GetCloudEventAttribute(message, "time");
         if (time != null) cloudEvent.Time = DateTime.Parse(time);
         string? source = GetCloudEventAttribute(message, "source");         
         if (source != null) cloudEvent.Source = new Uri(source, UriKind.RelativeOrAbsolute);
         string? subject = GetCloudEventAttribute(message, "subject");
         if (subject != null) cloudEvent.Subject = subject;
         string? type = GetCloudEventAttribute(message, "type");
         if (type != null) cloudEvent.Type = type;
         string? id = GetCloudEventAttribute(message, "id");
         if (id != null) cloudEvent.Id = id;
         foreach (var header in message.Headers)
         {
            var key = header.Key;
            if (key.StartsWith(kafkaCloudEventPrefix))
            {
                  var attributeName = key.Substring(kafkaCloudEventPrefix.Length);
                  if (ceAttribs.Any(a=>a==attributeName))
                  {
                     continue;
                  }
                  cloudEvent[attributeName] = Encoding.UTF8.GetString(header.GetValueBytes());
            }
         }
         return cloudEvent;
      }
   }
   catch (Exception e)
   {
      _logger.LogError(e, "Error extracting CloudEvent from Message.");
      throw;
   }
}
{%- endmacro -%}


{%- macro testFixtureClass(namespace) %}

using System;
using System.Threading.Tasks;
using DotNet.Testcontainers.Builders;
using DotNet.Testcontainers.Containers;
using Xunit;

namespace {{ namespace }}
{
   public class KafkaEmulatorFixture : IAsyncLifetime
   {
      public TestcontainersContainer KafkaContainer { get; }

      public KafkaEmulatorFixture()
      {
         KafkaContainer = new TestcontainersBuilder<TestcontainersContainer>()
               .WithImage("confluentinc/cp-kafka:latest")
               .WithPortBinding(9092, 9092)
               .WithEnvironment("KAFKA_BROKER_ID", "1")
               .WithEnvironment("KAFKA_ZOOKEEPER_CONNECT", "localhost:2181")
               .WithEnvironment("KAFKA_ADVERTISED_LISTENERS", "PLAINTEXT://localhost:9092")
               .WithEnvironment("KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR", "1")
               .Build();
      }

      public async Task InitializeAsync()
      {
         await KafkaContainer.StartAsync();
      }

      public async Task DisposeAsync()
      {
         await KafkaContainer.StopAsync();
      }
   }
}
{%- endmacro -%}
